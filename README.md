# sql-challenge

Module 9 Challange - SQL

Background
It’s been two weeks since you were hired as a new data engineer at Pewlett Hackard (a fictional company). Your first major task is to do a research project about people whom the company employed during the 1980s and 1990s. All that remains of the employee database from that period are six CSV files.

For this project, you’ll design the tables to hold the data from the CSV files, import the CSV files into a SQL database, and then answer questions about the data. That is, you’ll perform data modeling, data engineering, and data analysis, respectively.

Beggining steps:
    1)Create repo and related folders.
    2)Import CSV data and review the material to create a ERD
    3)Continue to Data Modeling and Engineering

Reviewing the data and creating the ERD. This allows you to put together the data and see what are the primary keys and foreign keys. This map allows you to be better suited to build your data model. Once in Data modeling phase, I had to go back to edit my ERD to make sure i had the proper path showing how code was written. The ERD certianly helps prepare for the table creating.

Data Modeling, The ERD helps build this out but once you're building the tables and importing the CSV data. You quickly understand where you errors might be. I specifically had trouble with a few tables to start, but once i moved things around and a series a trial and error the problems were figured out. The onto Data Engineering.

Data Engineering, is where the tables of the data were compiled to show the data and how it relates and get the data we were seeking to compare. There were some challenges in this section, but various online resources and trial and error helped elevate the process and helped me figure out how to code everything to get the desired tables. 

Conclusion: It was certianly interesting to look at the tables of the raw data that was manipulated. It brings together what might be looked after in a real life scenario. 
